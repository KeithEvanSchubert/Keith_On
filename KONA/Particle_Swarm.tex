\documentclass{article}
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\title{Particle Swarm Optimization to Superiorization}
\author{Keith Evan Schubert}
\begin{document}

\section{Particle Swarm Optimization}
PSO can be done for constrained, non-constrained, multi-objective, etc.  Essentially the idea is to get a group (swarm) of semi-independent searchers (particles) looking for the solution.
\subsection{Particles}
Each particle is an agent that is cooperatively searching the solution space.  The particles, numbered $i\in\{1:n\}$ at step $k$ store:
\begin{enumerate}
\item Current fitness, $f_{i,k}=f(x_i(k))$, and location, $x_i(k)$
\item Individual best fitness, $F_{i,k}=\max_{j\in\{1:k\}}f_{i,j}$, and the associated location, $X_{i,k}=x_i(j)$ such that
        $j=\argmax_{j\in\{1:k\}}f_{i,j}$, encountered so far
\item Global best fitness, $F_{g,k}=\max_{j\in\{1:k\},i\in\{1:n\}}f_{i,j}$, and location,
        $X_{g,k}=\argmax_{j\in\{1:k\},i\in\{1:n\}}f_{i,j}$
\item Current velocity, $v_{i,k}$
\end{enumerate}
evaluation of the $\max$ and $\argmax$ is trivial in this case since it is done iteratively and we can just compare to the current fitness and position.

\subsection{Constraints}
Constraints are handled a variety of ways:
\begin{description}
\item[Feasibility preserving] make a function that transform feasible points into new feasible points - typically assume linear/convex and a feasible start. These essentially replace the velocity and position generation.  Searching the boundary is difficult with inequality and/or non-linear constraints is very difficult.  Additionally the cost to force feasibility should be much higher than taking a feasibility step, ala superiorization.
\item[Penalty functions]  incorporate the constraints into the fitness by adding a penalty function to heavily penalize not meeting the constraints.
\item[Distinguish feasible and infeasible] treat feasible and infeasible points differently.  Some turn off feasibility constraints till a certain number of particles work and seek to increase the feasibility constraints that are on and work for the point.  Note on (evaluated) and off (not evaluated) are different than active (on boundary) and inactive (in interior).
\item[hybrid methods] combine some other method with swarm.  Often these are numerical methods, of mixed integer optimization.
\end{description}


\subsection{Parameters}
There are three basic parameters used to control the behavior of the algorithm and essentially control the weighting of the velocity weighting, which is how it gets a new guess.  The parameters are $\omega$ (weight to give current velocity), 
$\phi_p$ (the weight to give the particles best), and $\phi_g$ (the weight to give the global best).  These parameters can be thought of as learning parameters.

\subsection{Algorithm}
Each member of the swarm does the following at each iteration:
\begin{enumerate}
\item Calculate the fitness of its current guess/location in the solution space.  The fitness function is the cost function we are trying to minimize. \emph{This is expensive for many constraint methods.}
\item If a particle's current location has the best fitness it has personally encountered then it updates its personal best field with the location and fitness. \emph{ Trivial binary comparison.}
\item If a particle's current location has the best fitness any particle has encountered then it broadcasts the location and fitness and fitness, and updates its global best field.\ emph{ Asynchronous network broadcast.}
\item Calculate the next guess by:
    \begin{enumerate}
    \item Calculate new velocity, by $v_{i,k+1}=\omega\cdot v_{i,k} + \phi_p\cdot rand()\cdot(X_{i,k}-x_i(k)) + \phi_g\cdot rand()\cdot(X_{g,k}-x_i(k))$
    \item Calculate new position, by $x_i(k+1)=x_i(k)+v_i(k+1)$
    \end{enumerate}
    \emph{Feasibility preserving modifies this part for meeting the constraints.}
\end{enumerate}


\section{Particle Swarm Superiorization}


Each member of the swarm does the following at each iteration:
\begin{enumerate}
\item Calculate the fitness of its current guess/location in the solution space according to the unconstrained optimization problem.
\item If a particle's current location has the best fitness it has personally encountered then it updates its personal best field with the location and fitness.
\item If a particle's current location has the best fitness any particle has encountered then it broadcasts the location and fitness and fitness, and updates its global best field.
\item Calculate the next guess by:
    \begin{enumerate}
    \item Calculate new velocity, by $v_{i,k+1}=\omega\cdot v_{i,k} + \phi_p\cdot rand()\cdot(X_{i,k}-x_i(k)) + \phi_g\cdot rand()\cdot(X_{g,k}-x_i(k))+ \psi\cdot d_{feas}$
    \item Calculate new position, by $x_i(k+1)=x_i(k)+v_i(k+1)$
    \end{enumerate}
\end{enumerate}
Where $d_{feas}$ is the feasibility step from superiorization, and $\psi$ is its corresponding weight.

This method would be classified as hybrid, as intermediates are not guaranteed to be feasible, there is no penalty, and no distinction is made.  The parameter $\psi$ can incorporate relative weighting of the unconstrained optimization to the feasibility update ($\phi$ terms).
\end{document} 