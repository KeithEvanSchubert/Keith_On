The fundamental theorem of Calculus tells us that an integral of a function can be expressed in terms of the anti-derivative of the function.  Unfortuneately, not all functions have anti-derivatives that are expressable in known functions.  One of the most famous is the Gaussian probability distribution, which is given by\beqne^{-\left(\frac{x-\mu}{\sigma}\right)^{2}}.\eeqnThe anti-derivative of this important and frequently occuring function is unknown.  How do we handle it?  That is the subject of this chapter.\section{Riemann}We recall from Calculus that the integral is defined as\beqn\int_{a}^{b}{f(x)dx} = \lim_{n\rightarrow\infty}\sum_{j=1}^{n}f(p_{j})(x_{j}-x_{j-1}).\eeqnNow assume that all $n$ of the $x_{j}$ are evenly spaced on $[a,b]$.  We can then write\beqnh & = & \frac{b-a}{n} \\  & = & x_{j}-x_{j-1}.\eeqnWe can use this to get an expression for the Riemann Sum\beqn\int_{a}^{b}{f(x)dx} & = & \lim_{n\rightarrow\infty}\sum_{j=1}^{n}f(p_{j})(x_{j}-x_{j-1}) \\ & = & \lim_{n\rightarrow\infty}\sum_{j=1}^{n}f(p_{j})h \\ & = & \lim_{n\rightarrow\infty}h\sum_{j=1}^{n}f(p_{j}).\eeqnTo evaluate the integral numerically we are not able to take the limit, so we get\beqn\int_{a}^{b}{f(x)dx}  & \approx & h\sum_{j=1}^{n}f(p_{j}).\eeqnThe exact size of $n$ for the approximation to be good is a key aspect of numerical integration.  Note also that I have not specified what $p_{j}$ is, as this form allows you to do a left, right, mid-point, maximum, or minimum.  The basic idea here is that we are approximating the function by a constant on the interval.\setlength{\lll}{\textwidth}\addtolength{\lll}{-2\fboxsep}\addtolength{\lll}{-2\fboxrule}\noindent\fbox{%\begin{minipage}{\lll}\beqn\int_{a}^{b}{f(x)dx}  & \approx & h\sum_{j=1}^{n}f(p_{j}).\eeqn\end{minipage}}